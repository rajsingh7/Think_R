# Goodness of fit test for a multinomial experiment
myGoF.Test <- function(d,mu0){
e <- length(d)*mu0
chisq <- sum((table(d)-e)^2/e)
pchisq(chisq,length(unique(d))-1,lower.tail=F)
}
condition <- as.factor(c(rep("Excellent",46),rep("Good",83),rep("Fair",105),rep("Poor",16)))
o <- table(condition)
o
mu0 <- c(0.15,0.45,0.3,0.1)
myGoF.Test(condition, mu0)
chisq.test(o, p=mu0)
# Chisquare test of independence
data <- as.data.frame(rbind(c(174,132,90),c(54,72,78)))
row.names(data) <- c("Under 35","35 or Above")
names(data) <- c("Under Armour","Nike","Adidas")
chisq.test(data)
myIndependence.Test <- function(data){
r <- nrow(data)
c <- ncol(data)
fdata <- data
for (row in 1:r){
for (col in 1:c){
fdata[row,col] <- sum(data[row,])*sum(data[,col])/sum(data)
}
}
chisq <- sum((data - fdata)^2/fdata)
p <- pchisq(chisq,(r-1)*(c-1),lower.tail=F)
print(paste("the test statistic is ",round(chisq,4)," and the p value is ",round(p,4)))
}
myIndependence.Test(data)
# Goodness of fit test for normality
myGoFNormal.Test <- function(data, mu, sd,k = 6){
n <- length(data)
breaks <- seq(min(data),max(data),(max(data)-min(data))/k)
oi <- table(cut(data, breaks=breaks))
pi <- diff(pnorm(c(-Inf,breaks[2:k],Inf), mu,sd))
ei <- n*pi
chisq <- sum((oi-ei)^2/ei)
p <- pchisq(chisq,df = k-3,lower.tail=F)
c(chisq,p)
}
set.seed(123)
data <- rnorm(100,10,1)+rnorm(100,0.1,0.1)
myGoFNormal.Test(data, 10,1)
myGoFNormal.Test(data, 10.1,1.1)
myGoFNormal.Test(data, mean(data),sd(data))
# Jarque-Bera test for normality
myJB.Test <- function(data){
library(e1071)
n = length(data)
S <- skewness(data)
K <- kurtosis(data)
JB <- (n/6)*(S^2+K^2/4)
c(JB,pchisq(JB,2,lower.tail=F))
}
myJB.Test(data)
set.seed(123)
pdata <- rpois(10000,99)
hist(pdata)
myJB.Test(pdata)
# Chapter 13 Analysis of Variance
# One-Way ANOVA
data <- cbind.data.frame(c(-11,-13,-10,-8,-13,-15,-12,-8,-13,-8,-13,-10,-12,-13,-15),
c(rep("A",3),rep("B",4),rep("C",5),rep("D",3)))
names(data) <- c("response","treatment")
data$response <- as.numeric(as.character(data$response))
aov(response~treatment,data)
myOneWay.ANOVA <- function(data, response, treatment){
nT <- nrow(data)
c <- length(unique(data[,treatment]))
library(dplyr,quietly = T)
dataByTreatment <- group_by(data, treatment)
summarytable <- summarise(dataByTreatment, m = mean(response), s = sd(response), num = n())
summarytable <- mutate(summarytable,
gM = sum(data[,response])/nT,
STR = num*(m-gM)^2,
SE = (num-1)*s^2)
SSTR <- sum(summarytable$STR)
MSTR <- SSTR/(c-1)
SSE <- sum(summarytable$SE)
MSE <- SSE/(nT-c)
Fscore <- MSTR/MSE
p <- pf(Fscore,c-1,nT-c,lower.tail = F)
print(paste("SSTR: ",round(SSTR,4),
" SSE: ",round(SSE,4),
" F value: ",round(Fscore,4),
" df1,df2 ",c-1," ",nT-c,
" p value: ",round(p,4)))
summarytable
}
myOneWay.ANOVA(data,"response","treatment")
stable <- summarytable
# not perfect, only works if the response is named "response", so is with treatment
# Fisher's LSD
myFisher.LSD <- function(stable, alpha){
c <- nrow(stable);nT <- sum(stable$num);SSE <- sum(stable$SE);MSE <- SSE/(nT-c);
between <- diff <- lwr <- upr <- vector();
for (i in 1:(c-1)){
for (j in (i+1):c){
between <- c(between, paste(stable$treatment[i],"~",stable$treatment[j]))
diff <- c(diff, stable$m[i]-stable$m[j])
margin <- qt(alpha/2,nT-c,lower.tail = F)*sqrt(MSE*(1/stable$num[i]+1/stable$num[j]))
lwr <- c(lwr, (stable$m[i]-stable$m[j]-margin))
upr <- c(upr, (stable$m[i]-stable$m[j]+margin))
}
}
rtable <- cbind.data.frame(between,diff,lwr,upr)
rtable
}
myFisher.LSD(stable, 0.05)
# Tukey's HSD method
aov.model <- aov(response~treatment,data)
TukeyHSD(aov.model)
myTukey.HSD <- function(stable, alpha){
balance = F
if (length(unique(stable$num))==1){balance = T}
c <- nrow(stable);nT <- sum(stable$num);SSE <- sum(stable$SE);MSE <- SSE/(nT-c);
between <- vector();diff <- vector();lwr <- vector();upr <- vector()
for (i in 1:(c-1)){
for (j in (i+1):c){
between <- c(between, paste(stable$treatment[i],"~",stable$treatment[j]))
diff <- c(diff, stable$m[i]-stable$m[j])
if (balance == F){
margin <- qtukey(alpha,c,nT-c,lower.tail = F)*sqrt(MSE/2*(1/stable$num[i]+1/stable$num[j]))
}
else{
margin <- qtukey(alpha,c,nT-c,lower.tail = F)*sqrt(MSE/(nT/c))
}
lwr <- c(lwr, (stable$m[i]-stable$m[j]-margin))
upr <- c(upr, (stable$m[i]-stable$m[j]+margin))
}
}
rtable <- cbind.data.frame(between,diff,lwr,upr)
rtable
}
myTukey.HSD(stable, 0.05)
# Two-Way ANOVA: No Interaction
v <- c(18,35,46,75,25,45,58,90,26,43,62,110)
edu <- rep(c("HighSchool","Bachelors","Masters","Phd"),3)
employ <- c(rep("Education",4),rep("Financial",4),rep("Medical",4))
data <- cbind.data.frame(v,edu,employ)
aov.model <- aov(v ~ edu + employ, data)
summary(aov.model)
TukeyHSD(aov.model)
# Two-Way ANOVA: With Interaction
education <- c(20,25,22,30,35,34,46,47,50,79,78,74)
financial <- c(27,25,25,44,46,48,50,58,56,90,92,95)
medical   <- c(26,24,25,42,43,45,62,56,60,90,100,105)
factorB <- rep(c(rep("High School",3),rep("Bachelors",3),rep("Masters",3),rep("PhD",3)),3)
factorA <- c(rep("Education",12),rep("Financial",12),rep("Medical",12))
data <- cbind.data.frame(c(education,financial,medical),factorA,factorB)
names(data)[1] = "Salary"
aov.model <- aov(Salary~factorA*factorB, data)
summary(aov.model)
# Chapter 14 Regression Analysis
# Covariance and Correlation Coefficient
set.seed(123)
x <- rnorm(100,1,0.1)
y <- 10*x + rnorm(100,0,0.2)
plot(x,y, pch = 19)
myCor.Test <- function(x,y,tail="Two-tail"){
n <- length(x); df <- length(x)-2;
t <- cor(x,y)*sqrt((length(x)-2)/(1-cor(x,y)^2))
if (tail == "Right-tail"){p <- pt(t, df, lower.tail = F)}
else if (tail == "Left-tail"){p <- pt(t,df)}
else {p <- 2*pt(-1*abs(t),df)}
print(paste("for a ",
tail,
" test the t value is ",
round(t,4),
"the p value is ",
round(p,4)))
p
}
myCor.Test(x,y)
# Simple Linear Regression
set.seed(123)
x <- rnorm(100,1,0.1)
y <- 10*x + 2 + rnorm(100,0,0.2)
lm.model <- lm(y~x)
summary(lm.model)
b1 <- cov(x,y)/sd(x)^2
b0 <- mean(y)-b1*mean(x)
b1
b0
# Multiple Regression Model
y <- c(46,51,28,55,29,53,47,36)
x1 <- c(40,48,29,44,30,58,60,29)
x2 <- c(13,28,24,11,28,28,29,14)
data <- cbind.data.frame(y,x1,x2)
summary(lm(y~x1+x2,data=data))
# Chapter 15 Inference with Regression Models
# Test of Individual Significance
N <- length(y)
K <- 2
Se <- sqrt(sum(summary(lm(y~x1+x2,data))$residuals^2)/(N-K-1))
R2YH <- summary(lm(y~x1+x2,data))$r.squared
R2X2G2 <- summary(lm(x2~x1, data))$r.squared
Sy <- sd(y)
Sx2 <- sd(x2)
Sb2 <- Se/sqrt((1-R2X2G2)*Sx2^2*(N-1))
Sb2
Sy/Sx2*sqrt((1-R2YH)/((1-R2X2G2)*(N-K-1)))
summary(lm(y~x1+x2,data))$coefficients["x2", "Std. Error"]
# Test of Joint significance
SSR <- sum((model$fitted.values - mean(y))^2)
SSE <- sum((model$fitted.values - y)^2)
Fscore <- (SSR/K)/(SSE/(N-K-1))
Fscore
1-pf(Fscore, K,N-K-1)
summary(lm(y~x1+x2,data))
# General Test of Linear Restrictions
data$x3 <- c(5,5,3,6,3,5,5,4)
unrestrictedModel <- lm(y~.,data)
restrictedModel <- lm(y~x2+x3,data)
anova(restrictedModel,unrestrictedModel)
SSEu <- sum(unrestrictedModel$residuals^2)
SSEr <- sum(restrictedModel$residuals^2)
df1 <- 1
df2 <- 8-3-1
Fscore <- ((SSEr-SSEu)/df1)/(SSEu/df2)
Fscore
1-pf(Fscore,df1,df2)
# Interval Estimations for Predictions
model1 <- lm(y~.,data)
ynullhat <- model1$coefficients %*% c(1,40,13,5)
ynullhat
mdata <- data
mdata$x1 <- mdata$x1 - 40
mdata$x2 <- mdata$x2 - 13
mdata$x3 <- mdata$x3 - 5
s <- summary(lm(y~., mdata))
s
ynullhat + c(qt(0.025, 4),-qt(0.025, 4))*s$coefficients[1,2]
ynullhat + c(qt(0.025, 4),-qt(0.025, 4))*sqrt(s$coefficients[1,2]^2+s$sigma^2)
predict(model1, data[1,],level=0.95, interval="confidence")
predict(model1, data[1,],level=0.95, interval="prediction")
# Model Assumptions and Common Violations
plot(data$x1, model1$residuals, pch = 19)
plot(data$x2, model1$residuals, pch = 19)
plot(data$x3, model1$residuals, pch = 19)
plot(data$y, model1$residuals, pch = 19)
# Chapter 16 Regression Models for Nonlinear Relationships
# plot nonlinear relationship
sdata <- data
plot(data$x1, data$y, pch = 19)
# transformation
sdata$x1s <- data$x1^2
sdata$x1c <- data$x1^3
# summary see if improved?
# polynomial regression
summary(lm(y~x1, data))
summary(lm(y~x1+x1s, sdata))
summary(lm(y~x1+x1s+x1c, sdata))
# log-log linear regression model
llrmodel <- lm(log(y)~log(x1), data)
summary(llrmodel)
# unadjusted prediction
exp(cbind(rep(1,nrow(data)), log(data$x1)) %*% llrmodel$coefficients)
ujp <- exp(predict(llrmodel, data))
ujp
# adjuestd prediction
ajp <- exp(predict(llrmodel, data)+summary(llrmodel)$sigma^2/2)
ajp
# see prediction measure
cor(ujp, data$y)
cor(ajp, data$y)
sum((ujp-data$y)^2)
sum((ajp-data$y)^2)
# logarithmic model
lmodel <- lm(y~log(x1), data)
summary(lmodel)
cbind(rep(1,nrow(data)), log(data$x1)) %*% lmodel$coefficients
lp <- predict(lmodel, data)
lp
cor(lp, data$y)
sum((lp-data$y)^2)
# exponential model
emodel <- lm(log(y)~x1, data)
summary(emodel)
ep <- exp(predict(emodel, data)+summary(emodel)$sigma^2/2)
cor(ep, data$y)
sum((ep-data$y)^2)
# Chapter 17 Regression Models with Dummy Variables
# Dummy Variables
# dummy variable transformation function
dummyEncoding <- function(df, colname){
dummyDf <- as.data.frame(model.matrix(~df[,colname]))
names(dummyDf) <- paste(colname,as.character(levels(df[,colname])),sep="")
df[,colname] <- NULL
df <- cbind(df,dummyDf[,2:ncol(dummyDf)])
df
}
tdata <- data
tdata$x3 <- as.factor(tdata$x3)
dtdata <- dummyEncoding(tdata, "x3")
# individual t test
summary(lm(y~., tdata))
summary(lm(y~., dtdata))
# partial F test
modelwd <- lm(y~., dtdata)
modelwod <- lm(y~x1+x2, dtdata)
anova(modelwd, modelwod)
# interaction term
anova(lm(y~.+x2*x3, tdata),lm(y~.,tdata))
# binary variable
# linear probability model LPM
data$yp <- c(1,1,0,1,0,1,1,0)
lpm <- lm(yp ~ x1+x2, data)
predict(lpm, cbind.data.frame(x1,x2))
# logistic regression
logitmodel <- glm(yp~ x1 + x2, family = "binomial", data)
logit <- predict(logitmodel, data[,2:3])
exp(logit)/(1+exp(logit))
# Chapter 18 Time Series and Forecasting
# Smoothing techniques
library(tseries)
library(PerformanceAnalytics)
VBLTX_prices <- get.hist.quote(instrument="vbltx", start="2005-09-01", end="2010-09-30", quote="AdjClose",provider="yahoo", origin="1970-01-01",compression="m", retclass="zoo", quiet = TRUE)
FMAGX_prices <- get.hist.quote(instrument="fmagx", start="2005-09-01", end="2010-09-30", quote="AdjClose",provider="yahoo", origin="1970-01-01",compression="m", retclass="zoo", quiet = TRUE)
SBUX_prices <- get.hist.quote(instrument="sbux", start="2005-09-01",end="2010-09-30", quote="AdjClose",provider="yahoo", origin="1970-01-01",compression="m", retclass="zoo", quiet = TRUE)
index(VBLTX_prices) <- as.yearmon(index(VBLTX_prices))
index(FMAGX_prices) <- as.yearmon(index(FMAGX_prices))
index(SBUX_prices) <- as.yearmon(index(SBUX_prices))
all_prices <- merge(VBLTX_prices, FMAGX_prices, SBUX_prices)
colnames(all_prices) <- c("VBLTX", "FMAGX", "SBUX")
movingAverage <- function(ts, m){
nobs <- length(ts)
MAs <- vector()
for (i in 1:nobs){
if (i < m){
MAs <- c(MAs, NA)
}
else{
MAs <- c(MAs, mean(ts[(i-m+1):i]))
}
}
MAs
}
VBLTX_5_MA <- movingAverage(all_prices[,"VBLTX"], 5)
plot(x = c(1:length(VBLTX_5_MA)), y = VBLTX_prices, lwd = 2, type = "l", col = "black")
lines(c(2:(length(VBLTX_5_MA)+1)), VBLTX_5_MA, lwd = 2, col = "blue")
exponentialSmoothing <- function(ts, alpha = 0.2){
EAs <- vector()
EAs <- c(EAs, ts[1])
nobs <- length(ts)
for (i in 2:nobs){
EAs <- c(EAs, (alpha*ts[i]+(1-alpha)*EAs[i-1]))
}
EAs
}
VBLTX_EA <- exponentialSmoothing(all_prices[,"VBLTX"], 0.5)
lines(c(2:(length(VBLTX_EA)+1)), VBLTX_EA, type = "l", lwd = 2, col = "green")
#
SBUX_prices
movingAverage(SBUX_prices,4)
SBUX_MA4 <- movingAverage(SBUX_prices,4)
SBUX_MA4[2:(length(SBUX_MA4)-1)] + SBUX_MA4[3:length(SBUX_MA4)]
(SBUX_MA4[2:(length(SBUX_MA4)-1)] + SBUX_MA4[3:length(SBUX_MA4)])/2
length(SBUX_prices)
length(CMA)
SBUX_MA4 <- movingAverage(SBUX_prices,4)
CMA <- (SBUX_MA4[2:(length(SBUX_MA4)-1)] + SBUX_MA4[3:length(SBUX_MA4)])/2
length(CMA)
ratio_to_MA <- SBUX_prices[1:(length(SBUX_prices)-2)]/CMA
ratio_to_MA
index(CMA)
index(ratio_to_MA)
?as.yearmon()
index(ratio_to_MA)[1]
a <- index(ratio_to_MA)[1]
a
class(a)
as.Date(index(ratio_to_MA)[1])
as.Date(index(ratio_to_MA)[1])$m
b <- as.Date(index(ratio_to_MA)[1])
b
class(b)
b <- as.POSIXct(index(ratio_to_MA)[1])
b
b$d
index(ratio_to_MA)
index(ratio_to_MA)[1]
index(ratio_to_MA)[1][4:]
index(ratio_to_MA)[1].split()
index(ratio_to_MA)[1].strsplit(" ")
strsplit(index(ratio_to_MA)[1]," ")
as.character(index(ratio_to_MA))
as.character(index(ratio_to_MA))[1]
as.character(index(ratio_to_MA))[1][4:]
as.character(index(ratio_to_MA))[1][4:5]
strsplit(as.character(index(ratio_to_MA))[1]," ")
strsplit(as.character(index(ratio_to_MA))[1]," ")[2]
strsplit(as.character(index(ratio_to_MA))[1]," ")[[1]]
strsplit(as.character(index(ratio_to_MA))[1]," ")[[1]][2]
strsplit(as.character(index(ratio_to_MA))," ")[[1]][2]
strsplit(as.character(index(ratio_to_MA))," ")
index(ratio_to_MA)
as.Date(index(ratio_to_MA))
strptime(index(ratio_to_MA),"%m")
strptime(as.Date(index(ratio_to_MA)),"%m")
as.Date(index(ratio_to_MA))
a = as.Date(index(ratio_to_MA))[1]
a
strptime(a, fomart = "%m")
strptime(a, format = "%m")
strptime(a, format = "%M")
strptime(a, format = "%m")
?as.Date
?as.Date()
?as.Date()\
?as.Date()
as.Date(index(ratio_to_MA))
as.Date(index(ratio_to_MA),format = "%m")
as.Date(index(ratio_to_MA),format = "%m")
ratio_to_MA
strptime(index(ratio_to_MA))
strptime(index(ratio_to_MA), "%m")
strptime(index(ratio_to_MA), format = "%m")
strptime(as.Date(index(ratio_to_MA)), format = "%m")
as.Date(index(ratio_to_MA))
strptime(as.Date(index(ratio_to_MA)), "%Y-%m-%d")
a <- strptime(as.Date(index(ratio_to_MA)), "%Y-%m-%d")
a
a$m
a[1]$m
a[1
]
a <- strptime(as.Date(index(ratio_to_MA)), "%Y-%m-%d")
a
class(a)
a$h
a$wday
a$mon
index(ratio_to_MA)
index(ratio_to_MA)$mon
as.Date(index(ratio_to_MA))$mon
as.POSIXlt(index(ratio_to_MA))$mon
index(ratio_to_MA) <- as.POSIXlt(index(ratio_to_MA))$mon
as.POSIXlt(index(ratio_to_MA))$mon
index(ratio_to_MA) <- as.factor(as.POSIXlt(index(ratio_to_MA))$mon)
orders <- as.factor(as.POSIXlt(index(ratio_to_MA))$mon)
orders
months <- as.factor(as.POSIXlt(index(ratio_to_MA))$mon)
d <- cbind.data.frame(ratio_to_MA,months)
d
df <- cbind.data.frame(ratio_to_MA,months)
dbyMon <- group_by(df, months)
names(df)
summarise(dbyMon, seasonalindex = median(ratio_to_MA))
summarise(dbyMon, seasonalindex = median(ratio_to_MA, na.rm = T))
summarise(dbyMon, unadj.seaind = median(ratio_to_MA, na.rm = T))
seaind <- summarise(dbyMon, unadj.seaind = median(ratio_to_MA, na.rm = T))
seaind
seaind$adj.seaind <- seaind$unadj.seaind*12/sum(seaind$unadj.seaind)
seaind
seaind$adj.seaind
SBUX_prices
SBUX_df <- cbind.data.frame(SBUX_prices, as.factor(as.POSIXlt(index(SBUX_prices))$mon))
SBUX_df
names(SBUX_df)[2] = "months"
SBUX_df
seaind$adj.seaind
seaind
inner_join(SBUX_df, seaind, by = "months")
SBUX_df <- inner_join(SBUX_df, seaind, by = "months")
SBUX_df$SeaAdj.prices <- SBUX_df$AdjClose/SBUX_df$adj.seaind
SBUX_df
plot(SBUX_df$SeaAdj.prices)
plot(SBUX_df$SeaAdj.prices, pch = 19)
SBUX_df
SBUX_df$t <- 1:nrow(SBUX_df)
summary(lm(SeaAdj.prices~t+(t^2), data=SBUX_df))
SBUX_df$t2 <- (1:nrow(SBUX_df))^2
plot(SBUX_df$SeaAdj.prices, pch = 19)
summary(lm(SeaAdj.prices~t+t2, data=SBUX_df))
normaldata <- rnorm(999999, mean = 4, sd = 1.2)
normaldata <- rnorm(999999, mean = 4, sd = 1.2)
sample1 <- sample(normaldata, size = 1000, replace = F)
hist(sample1, border = 0, col = "black")
setwd("D:/GithubRepos/Think_R/Lectures")
set.seed(123)
mus <- vector() -> vars
for (i in 1:999){
d <- runif(9999,0,10)
mus <- c(mus,mean(d))
vars <- c(vars,var(d))
}
mus
mus
hist(mus)
set.seed(123)
mus <- vector() -> vars
for (i in 1:99999){
d <- runif(999,0,10)
mus <- c(mus,mean(d))
vars <- c(vars,var(d))
}
set.seed(123)
mus <- vector() -> vars
for (i in 1:9999){
d <- runif(999,0,10)
mus <- c(mus,mean(d))
vars <- c(vars,var(d))
}
mus
mean(mus)
var(mus)
10^2/12
var(mus)
var(mus)*999
